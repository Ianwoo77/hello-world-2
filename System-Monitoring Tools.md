# System-Monitoring Tools

To keep your system in optimum shape, need to be able to monitor it closely.

## Console-based Monitoring

It also benefits from enhanced use of the `/proc`file system, the virtual file system found on many UNIX. Through the `/proc`, can cimmunicate directly with the kernel to get a deep view of what is currently happening. Developers tend to use the `/proc`file system as a way of extracting info from the kernel and for their programs to manipulate that info into formats. Processes can also be controlled at the command line – which is just important cuz might sometimes have only a inteface… The process that comes from the kernel is assigned an identification number called PROCESS ID.

### Dispalying free and used memory with `free`

the `free`utility displays the amount of free and used memory in the system.

### Clean up ATP cache in Ubuntu

Uses APT (Advanced Package Tools) for installing, removing and managing software on the system. The APT package management system just keeps a cache of DEB packages in `/var/cache/apt/achives`, over time, this can grow quite large and hold a lot of packages you don’t need so:

```sh
sudo du -sh /var/cache/apt
```

`-s`– summarize, `-h`, human-readable.

```sh
sudo apt-get autoclean #just delete some tiny
sudo apt-get clean # delete apt cache
```

Removie older versions of Snap applications – 

The Unix Filesystem Hierarchy Standard, including pseudo file systems, navigation file management tools.

### The Linux file system

Everything in Linux just works through plain text files. file system – can think of it as a data table (or an index just) that creates apparent connections between individual files and groups of files with identifiable locaiton on the disk. So, if want your data to be reliably retrievable, you will need some kind of index that can consistently point you to the resource you are after. A file system uses such an index to provide the appearance of an organized set of directories and files within a single disk division known as `partition`.

All the files in a disk partition are kept in directories beneath the root directory, which is represented by the / character. fore `/etc/`which contains configuration files that define the way individual progams and services function. and `/var/`which contains *variable* files belonging to the system or individual apps whose content changes frequently through the course of normal system activities.

The command has no trash can – if you just delete something using `rm`or `rmdir`have no way get them back.

### File Globbing Pseudo file system

A normal file is a collection of data that can be just reliably accessed over and over again. By contrast, the contents of a Linux pseudo file, LIke those that might exist in the `/sys`and `/proc`directories – don’t really exist in the normal – A pseudo file’s contents are dynamically generated by the OS itself to just represent specific values.

`/dev/sda`, … Originally, sda stood for SCSI Device A, `/dev/fd0`, for floppy drive..

To get this kind of info, there are far simple ways.

Knowing that Linux organizes attched storage as *block devices*. in the `sys/block/`directory like:

```sh
cd /sys/block
ls # loop0...# loop is also pseudo device allows a file to be used through it.
cd sda
ls
```

### Showing’em who’s boss `sudo`

Once just confirm your identity by providing password, command will be treated as though it was issued by root user. By default, the user created during the initial linux installation will have `sudo`powers.

## Getting Help

### Man files

By accepted convention, creater and maintainer– known *man file* – manual. `info`– The `man`system is great – .

can access all system logs through `journalctl`fore:

```sh
journalctl | grep filename.php
```

can use the `grep`in seq to narrow your result further.

# Getting started with testing

In Go, almost everything is just `built-in`. This approach applies to testing as well. So can just automatically test your code using the built-in testing framework without installing any external tools or libraries.

For testing in Go, there are two main actors – 

- The test tool – simple command-line tool that comes built-in with Go, can use the `go test`command to compile and run tests automatically
- The testing package – the test tool only responsible for comipling and creating the necessary environment for the testing package – it is the testing package that helps you write and run tests.

The test tool itself is not a compiler, so uses the Go compiler to compile the test functions and the packages they depend on, and packs them in an executable binary.

In go, just organize code around packags. Can separate the package code to just multiple files in the same package for more straight navigation. Normally, a unit in Go is a *package*.

Unit tests are the fundamental part of automated testing, and when crafted correctly, they are just fast to run and help U design testable code

- Isolated
- Fast
- Deterministic - A UT is consistent and gives the same result every time it runs.

### Creating the url package

Go just has a special naming convention that makes a source code file a test file. `_test.go`suffix. 

### Writing a test function

In Go, use simple functions for testing. U write a function that begins with `Test`prefix and takes `*testing.T*`para. A signature includes the name of a func, the parameters it takes and returns, can make the test function correct by adding a `*testing.T*`parameter to it.

### Testing by signals

There needs to be a way to communicate with the testing package.

1. The testing package passes a `*testing.T`to test func so that the test func can communicate with the testing  pack.
2. The package marks a test func as failed if calls the `t.Fail()`.

```go
func Parse(rawUrl string) error {
	return errors.New("malformed url")
}
// ...
func TestParse(t *testing.T) {
	if err := Parse("Broken url"); err != nil {
		t.Fail()
	}
}
```

### Writing descriptive failure messages

When U read, couldn’t see why the test failed – then – don’t understand anything about the error message – 

```go
func TestParse(t *testing.T) {
	const rawUrl = "broken url"

	if err := Parse(rawUrl); err != nil {
		t.Logf("Parse (%q) err=%q, want nil", rawUrl, err)
		t.Fail()
	}
}
```

## Writing a true URL parser

The `FailNow()`method – Instead of calling the `Fail()`, need to use another method called `FailNow()`from `*T`. It marks the func as having failed and stops its exec by calling the `runtime.Goexit`.

### The `Fatal`and `FatalIf`

`Fatal`, equivalent to calling `Log`and `FailNow()`

`Fatalf`-- calling `Logf()`and `FailNow()`

```go
func TestParse(t *testing.T) {
	const rawUrl = "1.com"

	_, err := Parse(rawUrl)
	if err != nil {
		t.Fatalf("Parse(%q) err = %q, want nil", rawUrl, err)
	}
}
```

`Error`and `Errorf`– 

`t.Error`- calling `Log`and `Fail`

`t.Errorf`– calling `Logf`and `Fail`

```go
func TestParse(t *testing.T) {
	const rawUrl = "https://foo.com"

	u, err := Parse(rawUrl)
	if err != nil {
		t.Fatalf("Parse(%q) err = %q, want nil", rawUrl, err)
	}
	want := "https"
	if got := u.Scheme; got!=want {
		t.Errorf("Parse (%q).Scheme=%q; want %q", rawUrl, got, want)
	}
}
```

- arrangement – `want:="https"`
- act – `got := u.Scheme`
- assert – `if got!= want {}`

## Displaying Dynamic Data

Start in the `showSnippet`handler and add some code to render a new `show.page.html`file.

```go
// parse the template files...
ts, err := template.ParseFiles(files...)
if err != nil {
    app.serverError(w, err)
    return
}

// And then execute them just
err = ts.Execute(w, s) // s is Snippet struct
if err != nil {
    app.serverError(w, err)
}
```

Within the templates, any dynamic data that you pass in is represented by the `.`char.

```html
{{template "base" .}}

{{define "title"}}Snippet # {{.ID}} {{end}}

{{define "main"}}
	<div class="snippet">
		<div class="metadata">
			<strong>{{.Title}}</strong>
			<span>#{{.ID}}</span>
		</div>
		<pre><code>{{.Content}}</code></pre>
		<div class="metadata">
			<time>Created: {{.Created}}</time>
			<time>Expires: {{.Expires}}</time>
		</div>
	</div>
{{end}}
```

### Rendering Multiple Pieces of Data

`html/template`package allows you to pass in **one** – item of dynamic data when rendering a template. In real-world app there are often multiple pieces of dynamic data you want to display in the same page.

To achieve this is to wrap dynamic data in a struct which acts like a single *holding structure*

```go
type templateData struct {
	Snippet *models.Snippet
}
```

Then just updating the `showSnippet`handler to use this new.

Escaping – The `html/template`package automaticaly escapes any data that is yielded between {{}} tags.

nested templates – It’s really important to note that when you are invoking one template from another, dot need to be explicitly passed or *pipelined* to the template being invoked. like:

```html
{{template "base" .}}
{{block "sidebar" .}} {{end}}
```

## Template Actions and Functions

A block is shorthand for defining a template –

```html
{{define "name"}} T1 {{end}}
<!-- and then executing it in place -->
{{template "name" pipeline}}
```

==> `{{block "name" piepline}}`

To define a set of root templates that are then redefined.

- `{{if .Foo}} C1 {{else}} C2 {{end}}`
- `{{with .Foo}} c1 {{else}} C2 {{end}}` – if `.Foo`is not empty, set dot to the value of `.Foo` otherwise render C2
- `{{range .Foo}} C1 {{else}} C2 {{end}}`- if `.Foo`greater than 0 then loop over each element…

And also provides some template functions like:

`{{eq .Foo .Bar}}, {{ne .Foo .Bar}}, {{not .Foo}}, {{or .Foo .Bar}}`

`{{index .Foo i}}` – yields the value of `.Foo`at index i. Underlying type muse be `map, array, slice`..

`{{printf "%s-%s" .Foo .Bar}}`

`{{len .Foo}}, {{$bar := len .Foo}}`

### Using the `with`

A good to use the `{{with}}`is the `show.page.html`file that created in the previous like so:

Using the `if`and `range` – Update the `templateData`struct so that it contains a `Snippets`field for holding a slice of snippets like so:

```go
type templateData struct {
	Snippet  *models.Snippet
	Snippets []*models.Snippet
}
```

Then update the `home`handler function so that it fetches the latest snippets from our dbs. like: using the `{{if}}`and the `{{range}}`action:

```html
{{define "main"}}
	<h2>Latest Snippet</h2>
    {{if .Snippets}}
		<table>
			<tr>
				<th>Title</th>
				<th>Created</th>
				<th>ID</th>
			</tr>
            {{range .Snippets}}
				<tr>
					<td><a href="/snippet?id={{.ID}}">{{.Title}}</a></td>
					<td>{{.Created}}</td>
					<td>#{{.ID}}</td>
				</tr>
            {{end}}
		</table>
    {{else}}
		<p>There is nothing to display... yet!</p>
    {{end}}
{{end}}
```

## Caching Templates

Before add more, it’s good time to make some optimizations to codebase like:

1. Each and every time render a web page, our app reads and parses the relevant template files using the `template.ParseFiles()`func– could avoid this duplicated work by parsing the files once
2. There is duplicated code in the `home`and `showSnippet`handlers.

Tackle the first one – just create an in-memory map with the type `map[string]*template.Template`to cache the parsed templates, like:

```go
func newTemplateCache(dir string) (map[string]*template.Template, error) {
	cache := map[string]*template.Template{}

	// use the filepath.Glob to get a slice of all filepaths with the extension '.page.html'.
	// gives us a slice of all the page templates for the app
	pages, err := filepath.Glob(filepath.Join(dir, "*.page.html"))
	if err != nil {
		return nil, err
	}

	// loop through the pages one-by-one
	for _, page := range pages {
		// extract the file name from the full file path
		// and assign it to the name variable
		name := filepath.Base(page)

		ts, err := template.ParseFiles(page)
		if err != nil {
			return nil, err
		}

		ts, err = ts.ParseGlob(filepath.Join(dir, "*.layout.html"))
		if err != nil {
			return nil, err
		}

		ts, err = ts.ParseGlob(filepath.Join(dir, "*.partial.html"))
		if err != nil {
			return nil, err
		}

		// just add the template set to the cache
		cache[name] = ts
	}
	return cache, nil
}
```

The next step is to initialize this cache in the `main`and make it available to our handlers.

```go
// initialize a new template cache...
templateCache, err := newTemplateCache("./ui/html/")
if err != nil {
    errorLog.Fatal(err)
}
app := &application{errorLog:errorLog, infoLog: infoLog, snippets: &mysql.SnippetModel{db},
                    templateCache: templateCache}
```

So, at this point, just got a in-memory cache of the relevant template set for each of our pages. Add a new func:

```go
func (app *application) render(w http.ResponseWriter, r *http.Request, name string, td *templateData) {
	ts, ok := app.templateCache[name]
	if !ok {
		app.serverError(w, fmt.Errorf("the template %s does not exist", name))
		return
	}

	// execute the template set passing in any dynamic data.
	err := ts.Execute(w, td)
	if err != nil {
		app.serverError(w, err)
	}
}
```

## Caching Runtime Errors

As soon as begin adding dynamic behavior to our HTML templates there is a risk of encouner ..

Changing the parameters for the action method just tells MVC model binder that require the `Id`for the `Supplier`whose relationships the user is changing and sets its related `Products`.

# Wroking with Relationship 2 

Define oneToOne and MtM relationships.

- Add reciprocal properties and add a foreign key prop to the dept entity class
- Deal with the related objects spearately to ensure that add and update data correctly
- Create a junciton class that has one-to-many on the two related data types.

## Completing a one to one relationship

Two steps required – 

### Defining the Nav Prop – 

Between the `Supplier`and `ContactDetails`classes. like:

On the class `ContactDetails`: `public Supplier Supplier {get;set;}`and on the `Supplier`, also a single one.

### Selecting the DEPT entity class

Decide which class in the REL is the DEPT and define the FK prop on it. EF core stores objects as rows in dbs table. EF core adds a column to one of the tables and uses it to record the PK value of the related object. The FK column and class whose table contains the FK column is called *DEPT entity*. other – whose table don’t contain the FK column is called *PRIN entity*.

In the one-many – the many is always DEPT. So, here,  just define the FK in the `ContactDetals`.

`public long SupplierId {get;set;}` - type for this is 

After this, need to create a migration – just can see:

```cs
migrationBuilder.CreateIndex(..., unique:true);
```

Working with the one one – Querying in a one-one is a simple task cuz know that you have onely one related object to deal with.

```cs
public class One2OneController : Controller
{
    private EFDatabaseContext context;
    public One2OneController(EFDatabaseContext context)=>
        this.context = context;

    public IActionResult Index()
    {
        return View(context.Set<ContactDetails>().Include(cd => cd.Supplier));
    }
}
```

The controller just defines an action method called `Index`that queries the dbs for all of the `ContactDetails`objectrs and related `Supplier`objects and uses them as the view model.

### Changing and Updating Related Objects

Can create and update related objects through either nav prop in a one-to-one. Just like:

```cs
public IActionResult Create() => View("ContactEditor");

public IActionResult Edit(long id)
{
    return View("ContactEditor",
        context.Set<ContactDetails>()
        .Include(cd => cd.Supplier).First(cd=>cd.Id==id));
}

[HttpPost]
public IActionResult Update(ContactDetails details)
{
    if(details.Id==0)
    {
        context.Add<ContactDetails>(details);
    }
    else
    {
        context.Update<ContactDetails>(details);
    }
    context.SaveChanges();
    return RedirectToAction("Index");
}
```

These actions follow just the same used – The `Create`and `Edit`are used to just select a view called `ContactEditor`. Need to provide the view that will allow the user to create or eidt .

## Changing One-to-One Relationships

Care must be taken when changing the rel between objects, especially with required relatinships. EF core doesn’t enforce the restrictions on relationships before sneding updates to the dbs.

The challenge with a required relationships is that you must avoid storing any dept that is not related to the PRIN. Namely, every `ContactDetails`object must be associated with a `Supplier`object. Attempting to store or update a `ContactDetails`object that isn’t related to a `Supplier`will cause an error.

And need to note that a required REL is applied in only one direction – the DEPT entity must be related to a PRIN but a PRIN does not have to be related to DEPT.

This presents two different scenarios for changing an object’s REL – the first is when you want to change a REL so that a DEPT entity will be related to a PRIN that is not currently in a REL. So like:…

# Creating Role Management Tools

Some applications enforce only two levels of authorization - authenticated users are allowed access to all the app’s feautures – while unauthenticated – no access or have less.

Core identity supports *roles* for app that require more granular authorization. Users are assigned to one or more roles, and their membership of those roles determines which features are accessible.

Roles are managed through the `RoleManager<T>`- `T`just the representation of roles in the dbs. When configured in the `program.cs`file, just selected the `IdentityRole`which is just the built-in class that identity provides to describe a role, which means that will be using the `RoleManager<IdentityRole>`class in this. just has:

- `CreateAsync(role)` – Creates a new role
- `DeleteAsync(role)` – Deletes the specified role
- `FindByIdAsync(id)`– Finds a role by its ID
- `FindByNameAsync(name)`– 
- `RoleExistsAsync(name)`- returns `true`if a role exists
- `UpdateAsync(role)`- stores changes to specified role
- `Roles`– returns the enumeration of the role that have been defined.

And the props of the `IdentityRole`-- 

- `Id`– contains the unique ID for the role
- `Name`- returns the role name

Membership of roles is managed through the methods provided by the `UserManager<T>` – 

- `AddToRoleAsync(user, role)`– add a user to a role
- `RemoveFromRoleAsync(user, role)`
- `GetRoleAsync(user)`– returns the roles for which the user is a member
- `GetUsersInRoleAsync(role)`– return users who are member of the specified role.
- `IsInRoleAsync(user, role)`– returns `true`if the user is a member of the specified role.

Create the `Pages/Roles`folder add `_Layout`.

## Enumerating and Deleting Roles

Add a razor page named `List.cshtml`wtih the content like:

```cs
public class ListModel : AdminPageModel
{
    public UserManager<IdentityUser> UserManager;
    public RoleManager<IdentityRole> RoleManager;

    public ListModel(UserManager<IdentityUser> userManager, RoleManager<IdentityRole> roleManager)
    {
        UserManager = userManager;
        RoleManager = roleManager;
    }

    public IEnumerable<IdentityRole> Roles { get; set; } = Enumerable.Empty<IdentityRole>();

    public void OnGet()
    {
        Roles = RoleManager.Roles;
    }

    public async Task<string> GetMembersString(string role)
    {
        IEnumerable<IdentityUser> users = await
            UserManager.GetUsersInRoleAsync(role);
        string result = users.Count() == 0
            ? "No Members"
            : string.Join(", ", users.Take(3).Select(u => u.UserName).ToArray());
        return users.Count() > 3 ? $"{result}, (plus others)" : result;
    }

    public async Task<IActionResult> OnPostAsync(string id)
    {
        IdentityRole role = await RoleManager.FindByIdAsync(id);
        await RoleManager.DeleteAsync(role);
        return RedirectToPage();
    }
}
```

```html
@page
@model Advanced.Pages.Roles.ListModel

<table class="table table-sm table-bordered">
    <tr>
        <th>ID</th>
        <th>Name</th>
        <th>Members</th>
        <th></th>
    </tr>
    @if (Model.Roles.Count() == 0)
    {
        <tr>
            <td colspan="4" class="text-center">No Roles</td>
        </tr>
    }
    else
    {
        foreach (IdentityRole role in Model.Roles)
        {
            <tr>
                <td>@role.Id</td>
                <td>@role.Name</td>
                <td>@(await Model.GetMembersString(role.Name))</td>
                <td class="text-center">
                    <form asp-page="List" method="post">
                        <input type="hidden" name="Id" value="@role.Id"/>
                        <a class="btn btn-sme btn-warning" asp-page="Editor"
                           asp-route-id="@role.Id" asp-route-mode="edit">
                            Edit
                        </a>
                        <button type="submit" class="btn btn-sm btn-danger">
                            Delete
                        </button>
                    </form>
                </td>
            </tr>
        }
    }
</table>
```

So, the roles are enumerated, along with the name of up to 3 of the role members or placeholder.

### Creating Roles

Add :

```cs
public class CreateModel : AdminPageModel
{
    public RoleManager<IdentityRole> RoleManager;
    public CreateModel(RoleManager<IdentityRole> roleManager)
    {
        RoleManager = roleManager;
    }

    [BindProperty]
    public string Name { get; set; } = null!;

    public async Task<IActionResult> OnPostAsync()
    {
        if (ModelState.IsValid)
        {
            IdentityRole role= new IdentityRole { Name = Name };
            IdentityResult result= await RoleManager.CreateAsync(role);
            if(result.Succeeded)
            {
                return RedirectToPage("List");
            }
            foreach(IdentityError error in result.Errors)
            {
                ModelState.AddModelError("", error.Description);
            }
        }
        return Page();
    }
}
```

The user is presented with a form containing an `input`element to specify the name of the new role.When the from is submitted, the `OnPostAsync`creates a new `IdentityRole`obj and passes it to the `CreateAsync`.

### Assigning Role Membership

To add support for managing role memberships, need add the `Editor.cshtml`.

```cs
public class EditorModel : AdminPageModel
{
    public UserManager<IdentityUser> UserManager;
    public RoleManager<IdentityRole> RoleManager;

    public EditorModel(UserManager<IdentityUser> usrManager,  RoleManager<IdentityRole> roleManager)
    {
        UserManager = usrManager;
        RoleManager = roleManager;
    }

    public IdentityRole Role { get; set; } = new();

    public Task<IList<IdentityUser>> Members() =>
        UserManager.GetUsersInRoleAsync(Role.Name);

    public async Task<IEnumerable<IdentityUser>> NonMembers() =>
        UserManager.Users.ToList().Except(await Members());

    public async Task OnGetAsync(string id)
    {
        Role= await RoleManager.FindByIdAsync(id);
    }

    public async Task<IActionResult> OnPostAsync(string userid, string rolename)
    {
        Role = await RoleManager.FindByNameAsync(rolename);
        IdentityUser user = await UserManager.FindByIdAsync(userid);
        IdentityResult result;
        if(await UserManager.IsInRoleAsync(user, rolename))
        {
            result = await UserManager.RemoveFromRoleAsync(user, rolename);
        }else
        {
            result = await UserManager.AddToRoleAsync(user, rolename);
        }
        if(result.Succeeded)
        {
            return RedirectToPage();
        }
        else
        {
            foreach(IdentityError err in result.Errors)
            {
                ModelState.AddModelError("", err.Description);
            }
            return Page();
        }
    }
}
```

The user is presented with a table showing the userswho are members of the role and with a table showing nonmembers – Each row contains a `Change`button that submits the form.

# Routing

Is just fundamental concept when building web app. In more modern server-based framework such as MVC or RPs, those pages are dynamically compiled on the server before being sent to the client.

## Introducing Client-side routing

With SPAs – all of the pages reside on the client and navigating between them is handled by a client-side router.

### Blazor’s Router

The router is just another component – `App.Razor`file.

```html
<Router AppAssembly="@typeof(Program).Assembly">
	<Found Context="routeData">
    	<RouteView RouteData="@routeData"
                   DefaultLayout="@typeof(MainLayout)" />
    </Found>
    <NotFound>
    	...
    </NotFound>
</Router>
```

1. The router uses reflection to scan for page components
2. The `Found`is where page components that match a requested route are loaded.
3. The `NotFound`is shown when the router can’t find a match for the requested route.

There are componetns that have  a special directive declared in them called `@page`– It knows assembly could be in multiple assemblies. The `@page`allows to specify what route the component will be loaded for. Blazor has infrastructure that lives in the Js world.

The URL that the link points to is passed to a *Js service* called `NavigationManager`. When the C# `NavigationManager`receives the event, updates its URI prop – this stores the current URL so component can access it if required.

## Navigating between Pages  Programmatically

Programmatic navigation is achieved via the `NavigationManager.NavigateTo()`– use this to redirect users. Need to create a new component in the folder – `TrailSearch.Razor`– will house the search box and logic.

```html
<p class="mt-4">
    <input @onkeydown="SearchForTrail"
           @bind="_searchTerm"
           @bind:event="oninput"
           type="text"
           placeholder="Search for a trail..."
           class="form-control form-control-lg"/>
</p>
```

By default, the binding happens when the control loses focus. So just add to the `SearchPage.razor`file.

## Passing data between pages using Route Parameters

When navigating between pages, there are times want to pass arbitrary data as part of the URL. like:

```cs
@page "/search/{searchTerm}"

<PageTitle>Search Trails - Blazing Trails</PageTitle>

<h3>Search Results for "@SearchTerm"</h3>

@code {

    [Parameter]
    public string SearchTerm { get; set; } = default!;

}
```

now can access the search term just programmatically.

```cs
protected async override Task OnInitializedAsync()
{
    try
    {
        var allTrails = await Http.GetFromJsonAsync<IEnumerable<Trail>>(
            "trails/trail-data.json");
        _searchResults = allTrails!
            .Where(x => x.Name.Contains(SearchTerm,
                StringComparison.CurrentCultureIgnoreCase)
                        || x.Location.Contains(SearchTerm,
                            StringComparison.CurrentCultureIgnoreCase));
    }
    catch (Exception ex)
    {
        Console.WriteLine($"There was a problem loading trail data: {ex.Message}");
    }
}
```

One extra feature is the breadcrumb section at the top of the page. This is to allow easy navigation back to the home.

```html
<nav aria-label="breadcrumb">
    <ol class="breadcrumb">
        <li class="breadcrumb-item">
            <a href="/">Home</a>
        </li>
        <li class="breadcrumb-item active"
            aria-current="page">Search</li>
    </ol>
</nav>
```

## Handling multiple routes with a single component

It’s possible to have a single component be responsible for multiple routes. This can be useful for several reasons. Can be useful for several – moving to a new structure and need to support both the old and new versions for a period. Another is functinali

# Creating the Example Project

## Creating the project structure

To define the basic data type around which the app is based just add:

```ts
export class Product {
  constructor(public id?: number, public name?: string,
              public category?: string, public price?: number) {
  }
}
```

Creating the datasource and repository – To provide the app with some initial data, created: to complete the data model, just define the module. like:

```ts
@NgModule({
    providers:[Model, StaticDatasource]
})export class ModelModule{}
```

## Creating the Message Module

The messages module just contain a service that is used to report messages or errors that should be displayed to the user and a component that presents them.

### Creating the Message model and Service

in the `message`folder:

```ts
export class Message {
    constructor(public text: string, public error: boolean = false) {
    }
}
```

The `Message`class defines props that present the text that will be dislayed to the user and whether the message presents an error. Then add `message.service.ts`file to define the services.

```ts
@Injectable()
export class MessageService {
    messages: Observable<Message>= new ReplaySubject<Message>(1);
    reportMessage(msg:Message) {
        (this.messages as Subject<Message>).next(msg);
    }
}
```

Angular *services don’t support output props*, but can still use the features provided by the **RxJS** package to sents events. `reportMessage()`method that sends a new event through a `ReplaySubject<Message>`– this service is essentially used to provide access to the observable/subject.

### Creating the Component and Tempalte

Can create a component that will display them to the user.

```ts
@Component({
    selector: "paMessage",
    templateUrl: "message.component.html",
})
export class MessageComponent {
    lastMessage?: Message;

    constructor(messageService: MessageService) {
        messageService.messages.subscribe(msg => this.lastMessage = msg);
    }
}
```

Component receives a `MessageService`object as its ctor arg and subscribes to the event it emits in order to receive messages. – the most recent of which is assigned to a property called `lastMessage`.

```html
<div *ngIf="lastMessage"
     class="bg-primary text-white p-2 text-center"
     [class.bg-danger]="lastMessage.error">
    <h4>{{lastMessage.text}}</h4>
</div>
```

```ts
@NgModule({
    imports: [BrowserModule],
    declarations: [MessageComponent],
    exports: [MessageComponent],
    providers: [MessageService]
})
export class MessageModule {
}
```

## Creating the Core Module

The core module will contain the central functionality of the app – built on features that were.. Creating the shared State service – going to add a service that records the current mode.

```ts
export enum MODES {
    CREATE, EDIT
}

export interface StateUpdate {
    mode: MODES
    id?: number
}

@Injectable()
export class SharedState {
    private modeValue: MODES = MODES.EDIT;
    private idValue?: number;

    constructor() {
        this.changes = new Subject<StateUpdate>();
    }

    get id(): number | undefined {
        return this.idValue;
    }

    get mode(): MODES {
        return this.modeValue;
    }

    changes: Observable<StateUpdate>;

    update(mode: MODES, id?: number) {
        this.modeValue = mode;
        this.idValue = id;
        (this.changes as Subject<StateUpdate>).next({
            mode: this.modeValue, id: this.idValue
        });
    }
}
```

This contains two `get-only`props that reflect the current mode and the ID of the data model object. The state is changed using the `update`which sends out events through an RxJS  `Subject`.

### Creating the Table Component

This just the main focal point in the app. Providing accessto other areas of functionality… Then need to create the Table and Form component … A single component will present a form used to both create new products and edit existing ones. The `SharedState`service provides events that are used to change the details of the form.

Then just creating the Form component Template – `form.component.html`

```ts
@NgModule({
    imports: [BrowserModule, FormsModule, ModelModule],
    declarations: [TableComponent, FormComponent],
    exports: [ModelModule, TableComponent, FormComponent],
    providers: [SharedState],
})export class CoreModule{}
```

Then just complete the proj.

Adding `mergeMap`to example means replacing `map(wordString=>wordString.split(...))`, with.. This results in all following operators being called many times.

## Debugging an Observable Stream

This inner observable keeps thing simple when it comes to managing the split data. Debugging was just easy when there was only one observable, how can peek into a running observable chain to see.. `tap`operator does not modify any of the in-flight data or observables surrounding it. It allow to peek into what is going on inside the stream. like:

```ts
fromEvent<any>(textbox, 'keyup')
.pipe(
	map(event=> event.target.value),
    mergeMap(wordString=>
            from(wordString.split("/\s+/"))
            .pipe(
    map(pigLatinify),
    reduce((bigString, newString)=> bigString + ' ' + newString, '')
    )
            )
).subscribe(translate=>results.innerText=translate);
```

In the case of this, the array (namely, the map()’s result) passed into the inner observable contains nothing more complicated than strings. Using `mergeMap`extract the contents of the array simiplifies the operators that follow at the cost of adding a small amount of complexity in the form of an inner observable.

Another debugging tech is the `toArray`operator, a specialized version of `reduce`– waits for steam to complete, then emits all the events in the stream as a single array. like: This is just useful for debugging cuz it elmiinates the async nature of a stream.

```ts
fromEvent(somebutton, "click")
.pipe( take(3), toArray())
.subscribe(console.log);
```

And a third tool for this is the `repeat`which does exactly what think it does. It waits for that observable complete, then emits the value from the original.

```ts
of(1, 2, 3)
    .pipe(
        delay(1000),
        repeat(3)
    ).subscribe(console.log);
```

Typehead – Before observables, collecting the stream of `keypress`events, and parsing out possible results was difficult to pull off and filled with race conditions.

```ts
fromEvent<any>(typeaheadInput, 'keyup')
    .pipe(
        map((e: Event): string => (e.target as HTMLInputElement).value.toLowerCase()),
        tap(() => typeaheadContainer.innerHTML = ''),
        filter(val => val.length > 2),
        mergeMap(val =>
            from(usStates)
                .pipe(
                    filter(state => state.includes(val)),
                    map(state => state.split(val).join('<b>' + val + '</b>')),
                    reduce((prev: any, state) => prev.concat(state), [])
                ))
    ).subscribe(
        (stateList: string[]) => typeaheadContainer.innerHTML += "<br />" + stateList.join('<br>')
    );
```

Namely, every `keyup`event emitted from the `myInput`element sends a new event object down the stream. String to the new `filter`which works like for arrays.

The inner observable is made of list of states – another `filter`selects only the state with a name that contains the current value of the input, just using the `includes`operator. A `map`then bolds the insttance of the current query.

## Subject

RxJS Subject is a special type of Observable that allows values to be multicated to many Observers. while plain observables are unicast. 

### Pull vs. push

In pull, the consumer determines when it receives data from the data producer. Every Js function is a Pull system. The funtion is producer of data, and he code that calls the function is consuming by `pulling`out a single return value from its call.

What is push – In push systems, the producer determines when to send data to the consumer. Promises are the most common type of Push system in js. A `Promise`(producer)just delivers a resovled value to registered callbacks, but unlike functions, it is the `Promise`which in charge of determining precisely when that value is `pushed`on the callbacks.

An Observable is a producer of multiple values, pushing them to Observers (Consumers).

### Anatomy of an `Observable`

`Observable`is created using `new Observable`or a creation operator, are subscribed to with an `Observer`. Execute to deliver `next/error/complete`notification to the `Observer`.

The code inside `new Observable(observer=>...)`represents an *observable execution*. A lazy computation that only happens for each `Observer`that subscribes.

FORE, it is a good idea to wrap code in `subscribe`with `try/catch`block that will deliver an Error notification if it catches an exception like:

```ts
const observable = new Observable(observer => {
    try {
        observer.next(1);
        observer.complete();
    } catch (err) {
        observer.error(err);  // delivers an error if it caught one
    }
})
```

### Disposing Observable Executions

Cuz `Observable`executions may be just infinite - it’s common for an `Observer`to want to abort in .. need an API for canceling an execution. Once the `Observer`just done receiving values, it has to have a way to stop the execution, in order to avoid wasting computation power.

When `observable.subscribe()`called, the `Observer`gets attached to the newly created execution. This call also returns an obj like:

`const subscription = observable.subscribe(x=>console.log(x))`

The `Subscription`just represnets the ongoing execution, and has a minimal API which allows to cancel execution. With `subscription.unsubscribe()`can just cancel the ongoing execution.

```ts
from([10, 20, 30]).pipe(delay(100))
    .subscribe(console.log).unsubscribe(); // nothing displayed
```

And, each observable must define how to dispose resources of that executio when create the observable using `create()`. FORE:

```ts
const observable = new Observable(observer => {
    const intervalid = setInterval(() => {
        observer.next('hi');
    }, 1000);

    // provide a way of cancelling and disposing the interval resource
    return () => clearInterval(intervalid);
})
```

The returned func is conceptually equal to `subscription.unsubscribe()`.

Observer – Is a consumer of values delivered by an Observable. A set of callbacks, one for each type of notification delivered by the `Observable`.

```ts
const observer = {
    next: x=>...;
    error: err=> ...;
    complete: ()=>...
}
```

To use an `Observer`, provide it to the `subscribe()`of an `Observable`.

Observerss in RxJs may also be partial – if just don’t provide one of the callback, the execution of the `Observable`will still happen normally – except some types of notifications will be ignored.

There are just two kinds of operators – 

- Pipeable operators – like `filter`, `mergemap()`– do not change the existing Observable instance, just returns a new one, essentially a pure function which just takes one `Observable`as input and genertes another as output.
- Creation operators – are other kind of operator, which can be called as just standalone function to create a new `Observable`. `of()`fore.

For pipeable, in fact – `op()(obs)`, but quickly unreadable – `op4()(op3()(op2()))`… So:

`obs.pipe(op1(), op2(), op3(), op4())`. so just note that, `op4`is the last one to result return value.

Creation operators– can be used to create an `Observable`with some common predefined behavior. like: `interval()`.
