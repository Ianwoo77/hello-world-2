# Pseudo file Systems

A normal file is a collection of data that can be reliably accessed over and over again, even after a sytem reboot. By contrast, the contents of a Linux pseudo or called *virtual* file -- like those that might exist in the `/sys/`and `/proc/`directories, don’t really exist in the normal sense. A pseduo file’s contents are dynamically generated by the OS itself to represent specific values. like:

```sh
cat /sys/block/sda/size
cd /sys/block
ls # loop0...
cd sdb # sdb1...
```

All the currently available block devices -- a *loop device* is just a pseduo device that allows a file to be used as though it’s actually physical device.

Many flavors of linux solve this problem by just providing selected accounts with admin authority that under most circumstances are purely theoretical.

### Getting help

By accepted convention, Programmers also write a highly structured documentation manual known as *man file*. When installed, its man file is nearly always installed with it and can be viewed from the command linke by typing `man`followed by the command name.

info -- The man system is great if you happen to know the name of the command or program you are after -- but supose that the command name is the bit that you are missing. just type `info`at the command prompt, you will be transported to an environment that is -- 

Getting error info from system logs -- `journalctl`-- fore:

```sh
journalctl | grep filename.php
```

Just used the pipe -- output of the `journalctl`to the `grep`filter -- which will print to the screen only those lines that includes the string `fliename.php`

And in case you’d prefer to see only those lines that don’t contain some can:

```sh
journalctl | grep filename.php | grep -v error # -v inverted
```

## Building working environment

Once upon a time when U just wanted a new server to provide some web server or document share for .. need to research, request budget approval, negotiate, order.. The process from start to finish.. And when increasing demand on that service threatened to over-whlem 

Update package info for configured soureces and install some packages that will assist in configuring the official NGINX package repository -- 

```sh
apt-get update
apt install -y curl gnupg2 ca-certiicaates lsb-release debian-archive-keyring
apt-get update
apt-get install -y nginx
```

The `nginx`command allows you to interact with the nginx binary to check the version, list installed moduels, test configurations, and send signals to the master process.

### Key Files, directories and commands

The following -- 

- `/etc/nginx/`-- is the default *configuration* root for the NGINX server.
- `/etc/nginx/nginx.conf`-- is the default configuration entry point used by nginx service -- This configuration file sets up global settings for thigns like worker processes, tuning, logging, loading dynamic modules, and references to othe NGINX configuration files.
- `/etc/nginx/conf.d/`-- contains the default HTTP server configuration file.
- `/var/log/nginx/`-- default log location for nginx.

Commands -- 

- `nginx -h`-- show help meau
- `nginx -v`- show version
- `nginx -V`-- bulid info configuration arguments.
- `-t`-- tests the configuration
- `-T`-- tests configuration and prints the validated configuration to the screen.
- `nginx -s signal`-- `-s`sends a signal to the NGINX master process. -- can send `stop quit reload reopen...`

### Serving static content --

Need to serve static convent with NGINX -- overwrite the default HTTP srver configuration located in `/etc/nginx/conf.d/default.conf`with: fore:

```nginx
server {
    listen 8080 default_server;
    server_name www.example.com;

    location / {
        root /usr/share/nginx/html;
        # alias /usr/share/nginx/html;
        index index1.html;
    }
}
```

This configuration serves static files over HTTP on port 8080 from the directory `/usr/share/gninx/html`. The first line of this configuration defines a new `server`block -- this defines a new content for NGINX to listen for.

line 2 instructs listen on port 8080 the `default_server`-- to use this server as the default context for port 8080. Note that the `listen`directive also take a range of ports. And the `server_name`defines the hostname or the names of requests that should be directed to this server. With the `default_server`name set, can omit the `server_name`.

For the `location`block -- defines a configuration based on the PATH in the URL. The path, or porition of the URL afeter the domain, is referred as URI. uses the `/`to just match all requests. And the `root`directive shows NGINX where to look for static files when serving content for the given context.

### Graceful Reload -- 

Fore, need to reload your configuration without dropping packets -- Use the `reload`of Nginx to acheive a graceful realod of the configuration without stopping the sever like: `nginx -s reload`

This reloads the NGINX system using the NGINX binary to send a signal to the mater process. -- Reloading the NGINSX configuration without stopping the server provides the ability to change configurations on the fly without dorpping any packets. Dynamic environment, will need to change your load-balancing configuraiton at some point.

### High-performance Loading Balancing

Multiple copies of the same system are run -- and the load is distriuted over theml. As the laod increases, another copy of the system can be brought online. Hroizontal scaling -- Most enterprise architectures use a single, reverse proxy server to handle all incoming requests -- The proxy server then inspects each HTTP request and idientfies which backend system -- be it an Apache..Tomcat.. Should handle the request -- The reverse proxy then forwards the request to that server, allows the request to be processed.

- Client access all backend resources through a single web address
- The reverse proxy can serve static content -- reduce the load on app severs such as Express.
- The Nginx reverse proxy can navigate through firewalls that provtect backend
- The reverse can act as a cache or buffer
- User access control is simplified with a single point of access to site.

Steps -- 

1) Install
2) Add `proxy_pass`setting in a vritual host or the default config file
3) Map a context root to the URL of a backend server
4) optionally set headers for the nginx reverse poxy to use with the backend
5) Restart proxy, test.

## Self-testing code

One thing that can help give us confidence about the correctness of software is to write `tests`for it. While tests are useful whenever we write them -- it turns out that they are espeically useful when we write them first.. The most important reason to write tests first is that - to do that, need to have a clear idea of how the program should behave, from the user’s pointof view.

Trying to write code before we have a clear idea of what it should do is simply a wate of time. We are also likely to end up with a design whihc might be convenient from the point of view of the *implementer*. Wroking test-first encourages us to develop the system in small increments.

```go
func TestListItems(t *testing.T) {
	t.Parallel()
	input := []string{
		" a battery",
		"a key",
		"and a tourist map",
	}
	want := "You can see here a battery, a key, and a tourist map."

	got := ListItems(input)
	if want != got {
		t.Errorf("Want %q, got %q", want, got)
	}
}
```

Call the funtion `ListItem(input)`with test inputs -- check the result against the expected string, if are not the same, call `t.Errorf()`causes the test to fail.

### Verifying the test

First, need some feedback on whether the *test* itself is correct -- It’s helpful to think about ways the test could be *wrong*, and see if we can work out how to catch them.

Tests in go pass by default, unless you explicitly make them fail, so a test function with no code at all should always pass, like `Func TestAlwaysPasses(t *testing.T){}`

Until you’ve seen the test fail **as expected**, you don’t really have a test -- So can’t be *sure* that the test doesn’t contain logic bugs unless we have seen it fail when it’s supposed to. When *should* the test fail -- When `ListItems`returns the wrong result -- Write just enough code for the test function to return the wront result, and verify that the test fails in that case. just like:

```go
func ListItems(items []string) string {
    return ""
}
```

Using `cmp.Diff`to compare results -- Since part of the result is correct, but part isn’t, actually like the test to report the *difference* between `want`and `got`-- There is a useful 3rd-party package -- go-cmp, can use its `Diff`func to print just the difference between the two strings like:

```go
func TestListItems(t *testing.T) {
	t.Parallel()
	input := []string{
		"a battery",
		"a key",
		"a tourist map",
	}
	want := "You can see here a battery, a key, and a tourist map."

	got := ListItems(input)
	if want != got {
		t.Errorf(cmp.Diff(want, got))
	}
}
```

When two strings just differ, `cmp.Diff`shows which parts are the same, which parts are only in the first string, and which are only the second string.

### Test cases

Could write some new test fucntions, one for each case that want to check. But that seems a bit wasteful -- each test is going to do exactly the same thing -- call `ListItems`with some input, and check the result aginst expectations. Any time we want to do the same operation repeatedly, just with different data each imte, we can express this idea using a loop -- In go, use the `range`operator.

On of the nice thing about Go is that any time want to group some related bits of data into a single value like this:

```go
func TestListItems(t *testing.T) {
	type testCase struct {
		input []string
		want  string
	}

	cases := []testCase{
		{input: []string{
			" a battery",
			"a key",
			"and a tourist map",
		},
			want: "You can see here a battery, a key, and a tourist map.",
		},
	}
	t.Parallel()
	for _, tc := range cases {
		got := ListItems(tc.input)
		if tc.want != got {
			t.Errorf(cmp.Diff(tc.want, got))
		}
	}
}
```

Adding cases one at a time -- What new test cases should we add at this stage -- could add lots of cases at once, but since we feel pretty sure they will all fail, there is no point in that.

Quelling a panic -- Panics in Go are accompanied by a track trace, so we can work our way through it to see which line of code is the problem like.

### Tools for testing

Go’s built-in testing facilities -- Assume that you are now the point where you can explain to the computer exactly what you want -- An automated test is just another kind of computer program in principle, could just write some Go function that calls the system under test with some inputs. The Go stdlib provides a package named `testing`where can import and use in test code.

Go just looks for test code in files whose names end with `_test.go`-- No other files will be just considered when runinng tests. Not mandatory -- to put sources file containging that code in thes ame folder as the package they are testing. FORE:

## Database-driven Responses

There are many different data stores we could use for our app - each with different pros and cons. how to:

- Connect to MySQL from web app
- Creates a standalone modal package
- Use the appropriate functions in go’s database/sql package to execute different types of SQL statements.
- Prevent SQL injection attacks using placeholder parameters
- Use transactions.

Setting up MySQL -- `sudo apt install mysql-server`Once connected, the first thing we need to do is establish a dbs in MySQL to store all the data for our project -- fore:

```sql
CREATE DATABASE snippetbox CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
```

Just create tables first:

```sql
-- Create a `snippets` table.
CREATE TABLE snippets (
                          id INTEGER NOT NULL PRIMARY KEY AUTO_INCREMENT,
                          title VARCHAR(100) NOT NULL,
                          content TEXT NOT NULL,
                          created DATETIME NOT NULL,
                          expires DATETIME NOT NULL
);
-- Add an index on the created column.
CREATE INDEX idx_snippets_created ON snippets(created);
```

Each record in this table will have an integer `id`field which will act as the unique identifier for the text snippet. It will also have a short text `title`and the snippet content itself will be stored in the `content`field. Also keep some metadata about the times that the snippet was created and when it expires. Then add some data:

```sql
-- Add some dummy records (which we'll use in the next couple of chapters).
INSERT INTO snippets (title, content, created, expires)
VALUES ('An old silent pond',
        'An old silent pond...\nA frog jumps into the pond,\nsplash! Silence again.\n\n– Matsuo Bashō',
        UTC_TIMESTAMP(),
        DATE_ADD(UTC_TIMESTAMP(), INTERVAL 365 DAY));
INSERT INTO snippets (title, content, created, expires)
VALUES ('Over the wintry forest',
        'Over the wintry\nforest, winds howl in rage\nwith no leaves to blow.\n\n– Natsume Soseki',
        UTC_TIMESTAMP(),
        DATE_ADD(UTC_TIMESTAMP(), INTERVAL 365 DAY));
INSERT INTO snippets (title, content, created, expires)
VALUES ('First autumn morning',
        'First autumn morning\nthe mirror I stare into\nshows my father''s face.\n\n– Murakami Kijo',
        UTC_TIMESTAMP(),
        DATE_ADD(UTC_TIMESTAMP(), INTERVAL 7 DAY));
```

